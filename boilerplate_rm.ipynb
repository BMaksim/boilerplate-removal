{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boilerplate_rm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0+ciUWCyBlB1c1seyvXp0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXAdrvXK08yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e635fec4-45e9-4efd-f712-c47b6451ccab"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGid535gB58Q"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "from bs4 import NavigableString\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "ignore = {'head', 'iframe', 'script', 'meta', 'link', 'style', 'input', 'checkbox', 'button', 'noscript'}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWaCeRwgB-LS"
      },
      "source": [
        "dir = \"./drive/MyDrive/boilerplate_rm\"\n",
        "\n",
        "def get_tag_repr(tags, tags_dict):\n",
        "  result = np.zeros(len(tags_dict))\n",
        "  \n",
        "  for t, c in tags.items():\n",
        "    try:\n",
        "        idx = tags_dict.index(t)\n",
        "        result += np.array([0 if i != idx else c for i in range(len(tags_dict))])\n",
        "    except ValueError:\n",
        "      continue\n",
        "\n",
        "  return result\n",
        "\n",
        "def leavs_handler(node, tags=[], is_content=False):\n",
        "    new_tags = tags + [node.name]\n",
        "    if node.has_attr('__label'):\n",
        "        is_content = node['__label']\n",
        "\n",
        "    result = []\n",
        "    for c in node.children:\n",
        "        if isinstance(c, NavigableString):\n",
        "            # might be just whitespace\n",
        "            if c.string is not None and c.string.strip():\n",
        "                result.append((c, new_tags, is_content))\n",
        "        elif c.name is not None:\n",
        "            if c.name.lower() in ignore:\n",
        "                c.extract()\n",
        "            else:\n",
        "                result.extend(leavs_handler(c, new_tags, is_content))\n",
        "\n",
        "    return result\n",
        "\n",
        "data = []\n",
        "tags_list = defaultdict(int)\n",
        "for i in range(800):\n",
        "    try:\n",
        "        page = []\n",
        "        with open(dir + f\"/data/raw_html/{i}.html\", \"r\", encoding='cp850') as file:\n",
        "            content = file.read()\n",
        "            soup = bs(content, features='html5lib')\n",
        "\n",
        "        root = soup.find_all('html')[0]\n",
        "\n",
        "        for node, tags, is_content, in leavs_handler(root):\n",
        "            tags_dict = defaultdict(int)\n",
        "\n",
        "            for tag in tags:\n",
        "                tags_dict[tag] += 1\n",
        "\n",
        "            if is_content:\n",
        "                page.append([dict(tags_dict), node.string, 1])\n",
        "            else:\n",
        "                page.append([dict(tags_dict), node.string, 0])\n",
        "\n",
        "            for tag, count in tags_dict.items():\n",
        "                tags_list[tag] += count\n",
        "          \n",
        "        data.append(page)\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "ttt = sorted(tags_list.keys(), key=tags_list.get, reverse=True)[:50]\n",
        "\n",
        "for p in data:\n",
        "  for l in p:\n",
        "    l[0] = get_tag_repr(l[0], ttt)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ6a3DPtgDZi"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwjDpIYoGfid"
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import DistilBertModel, DistilBertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuNvzw_u-AQq"
      },
      "source": [
        "pretrained_weights = 'distilbert-base-uncased'\n",
        "tokinaizer = DistilBertTokenizer.from_pretrained(pretrained_weights)\n",
        "model = DistilBertModel.from_pretrained(pretrained_weights)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM5xdJXq42Rd"
      },
      "source": [
        "ids = []\n",
        "labels = []\n",
        "for p in data:\n",
        "  for l in p:\n",
        "    input_ids = tokinaizer.encode(l[1], add_special_tokens=True)\n",
        "    ids.append(input_ids)\n",
        "    labels.append(l[2])\n",
        "\n",
        "ids = pad_sequences(\n",
        "    ids,\n",
        "    maxlen=128,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "    )\n",
        "ids = torch.tensor(np.array(ids))\n",
        "labels = torch.tensor(np.array(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yryDzXcIrgBp"
      },
      "source": [
        "data_for_bert = TensorDataset(ids, labels)\n",
        "\n",
        "dataloader = DataLoader(data_for_bert, sampler=SequentialSampler(data_for_bert), batch_size=32)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sg_C8d38jq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e60b30-c223-4c2a-a1ee-690eb6115ea8"
      },
      "source": [
        "%%time\n",
        "result = []\n",
        "model = model.to(device)\n",
        "for batch in dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = model(b_input_ids)\n",
        "\n",
        "    features = last_hidden_states[0][:,0,:].detach().cpu().numpy()\n",
        "    result.extend(features)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 49s, sys: 426 ms, total: 10min 49s\n",
            "Wall time: 10min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icnLAqWJuT-2"
      },
      "source": [
        "i = 0\n",
        "for p in data:\n",
        "  for idx, l in enumerate(p):\n",
        "    l[1] = result[i]\n",
        "    l.append((idx+1)/len(p))\n",
        "    i += 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DMHHBUqXcD2"
      },
      "source": [
        "for p in data:\n",
        "  for l in p:\n",
        "    pos_v = []\n",
        "    for i in range(1,385):\n",
        "      pos_v.extend([np.sin(l[3]/(100**(2*i/768))), np.cos(l[3]/(100**(2*i/768)))])\n",
        "    l[1] += np.array(pos_v)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egmViT3_kKdv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "dataset = []\n",
        "dataset_labels = []\n",
        "\n",
        "for p in data:\n",
        "  for l in p:\n",
        "    dataset.append(np.hstack((np.array(l[0]), l[1])))\n",
        "    dataset_labels.append(l[2])\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(dataset, dataset_labels, test_size=0.33, random_state=111)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfkRlJ2iF7Jg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(solver='sag', max_iter=1000)\n",
        "lr_clf.fit(train_features, train_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK6386dUQ7fG"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "\n",
        "def report(labels, preds):\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    recall = recall_score(labels, preds, average=\"binary\")\n",
        "    f1 = f1_score(labels, preds, average=\"binary\")\n",
        "    precision = precision_score(labels, preds, average=\"binary\")\n",
        "    return {\"accuracy\": accuracy, \"recall\": recall, \"f1\": f1, \"precision\": precision}\n",
        "\n",
        "\n",
        "lr_preds = lr_clf.predict(test_features)\n",
        "lr_result = report(test_labels, lr_preds)\n",
        "\n",
        "print('lr: ', lr_result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}